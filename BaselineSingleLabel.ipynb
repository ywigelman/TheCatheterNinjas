{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "\n",
    "- building a baseline model using the cats vs. dogs architecture.\n",
    "- this baseline model includes a preprocessing steps of rescaling of all images to 80x80 size with a single channel (gray scale)\n",
    "- this baseline model is built for binary classification:\n",
    "    - output layer has a Sigmoid activation function \n",
    "    - loss function is binary_crossentropy\n",
    "    - chosen metrics is AUC with and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:01:36.390387Z",
     "start_time": "2021-01-24T16:01:36.358706Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:31:59.150799Z",
     "start_time": "2021-01-24T15:31:59.142117Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_META = 'train.csv'\n",
    "\n",
    "TRAIN_IMG_DIR = Path('train') \n",
    "TRAIN_RESIZE_DIR = Path('BaselineSingleLabel/train_resize') \n",
    "\n",
    "TEST_IMG_DIR = Path('test') \n",
    "TEST_RESIZE_DIR = Path('BaselineSingleLabel/test_resize') \n",
    "\n",
    "CASE = 'StudyInstanceUID'\n",
    "NEW_SIZE = (80,80)\n",
    "IMG_SIZE = (80, 80, 1)\n",
    "\n",
    "VALIDATION_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "RSCL = 1/255\n",
    "ACTIVATION = 'relu'\n",
    "N_FILTERS = 64\n",
    "FILTER2D_size = 1\n",
    "METRICS = [AUC(), 'accuracy']\n",
    "DENSE_DIM = 64\n",
    "OUT_DIM = 1\n",
    "OUT_ACTIVATION = 'sigmoid'\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'binary_crossentropy'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "AVAIL_CPU = None\n",
    "\n",
    "os.makedirs(TRAIN_RESIZE_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_RESIZE_DIR, exist_ok=True)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load meta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:26:02.812728Z",
     "start_time": "2021-01-24T15:26:02.772037Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_META)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:26:02.818510Z",
     "start_time": "2021-01-24T15:26:02.813871Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = df.select_dtypes(int).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:26:02.826343Z",
     "start_time": "2021-01-24T15:26:02.819569Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_img(img: np.array, ax=None, title: str='', cmap: str = 'gray'):\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.imshow(img, cmap=cmap, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "def preprocess(img_path: Path, processed_path: Path):\n",
    "    new_img = cv2.resize(cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE), NEW_SIZE)\n",
    "    cv2.imwrite(str(processed_path), new_img)\n",
    "    \n",
    "\n",
    "def validate_file(record: Path):\n",
    "    if record.is_file() & record.exists():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def numipy_train(meta: pd.DataFrame, img_dir: Path, suffix: str = '.jpg', \n",
    "                 case_col: str = CASE, labels_col = labels, \n",
    "                 scale=cv2.IMREAD_GRAYSCALE, image_dir_temp_col = 'images', \n",
    "                 cpu: int=None, binary_label: str = None):\n",
    "    \n",
    "    meta[image_dir_temp_col] = img_dir / (meta[case_col] + suffix)\n",
    "    msk = meta[image_dir_temp_col].apply(validate_file)\n",
    "    meta = meta[msk]\n",
    "    if binary_label:\n",
    "        binary_label = [label for label in labels_col if binary_label in label]\n",
    "        label_values = np.any(meta[binary_label], axis=1).values\n",
    "    else:\n",
    "        label_values = meta[labels_col].values\n",
    "    images = meta[image_dir_temp_col].to_list() \n",
    "    images = [(str(image), scale) for image in images]\n",
    "    with Pool(cpu) as p: images = p.starmap(cv2.imread, images)\n",
    "    return np.array(images), label_values\n",
    "\n",
    "\n",
    "def multi_preprocess(input_dir: Path, output_dir: Path, glob: str='*.jpg',\n",
    "                      size: tuple=NEW_SIZE, scale=cv2.IMREAD_GRAYSCALE, \n",
    "                      clip_limit=None, title_grid_size=None, \n",
    "                      cpu: int=None):\n",
    "    pool_lst = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for input_img in input_dir.glob(glob):\n",
    "        pool_lst.append((input_img, output_dir/input_img.name, size, scale, clip_limit, title_grid_size))\n",
    "    with Pool(cpu) as p: p.starmap(preprocess, pool_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "## preprocess train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:27:02.598843Z",
     "start_time": "2021-01-24T15:26:02.827250Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_preprocess(TRAIN_IMG_DIR, TRAIN_RESIZE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:27:10.298848Z",
     "start_time": "2021-01-24T15:27:02.600032Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_preprocess(TEST_IMG_DIR, TEST_RESIZE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert train into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:27:11.199786Z",
     "start_time": "2021-01-24T15:27:10.300317Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = numipy_train(df, TRAIN_RESIZE_DIR, binary_label='CVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T15:49:34.854458Z",
     "start_time": "2021-01-23T15:49:34.851131Z"
    }
   },
   "source": [
    "# basic CNN\n",
    "\n",
    "## make sequential model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:27:11.289582Z",
     "start_time": "2021-01-24T15:27:11.201478Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([Rescaling(RSCL, input_shape=IMG_SIZE, name='rescaling'),\n",
    "                    Conv2D(N_FILTERS, FILTER2D_size, activation=ACTIVATION, name='conv_1'), \n",
    "                    MaxPooling2D(name='max_pool1'),  \n",
    "                    Conv2D(N_FILTERS, FILTER2D_size, activation=ACTIVATION, name='conv_2'), \n",
    "                    MaxPooling2D(name='max_pool2'), \n",
    "                    Conv2D(N_FILTERS, FILTER2D_size, activation=ACTIVATION, name='conv_3'),\n",
    "                    MaxPooling2D(name='max_pool3'), \n",
    "                    Flatten(name='flat'), \n",
    "                    Dense(DENSE_DIM, activation=ACTIVATION, name='dense_1'), \n",
    "                    Dense(1, activation=OUT_ACTIVATION, name='out')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:27:11.295567Z",
     "start_time": "2021-01-24T15:27:11.290621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 80, 80, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 80, 80, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 40, 40, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 20, 20, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pool3 (MaxPooling2D)     (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flat (Flatten)               (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 418,177\n",
      "Trainable params: 418,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:27:11.299432Z",
     "start_time": "2021-01-24T15:27:11.296568Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"Checkpoint/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=1, \n",
    "save_best_only=False, save_weights_only=False, mode='auto')\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:32:08.417471Z",
     "start_time": "2021-01-24T15:32:08.406279Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T15:48:59.706856Z",
     "start_time": "2021-01-24T15:32:09.206598Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "753/753 [==============================] - 50s 66ms/step - loss: 0.1311 - auc: 0.6050 - accuracy: 0.9643 - val_loss: 0.1005 - val_auc: 0.7431 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00001: saving model to Checkpoint/weights.01-0.10.hdf5\n",
      "Epoch 2/100\n",
      "753/753 [==============================] - 47s 63ms/step - loss: 0.1152 - auc: 0.6653 - accuracy: 0.9743 - val_loss: 0.0982 - val_auc: 0.7587 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00002: saving model to Checkpoint/weights.02-0.10.hdf5\n",
      "Epoch 3/100\n",
      "753/753 [==============================] - 47s 63ms/step - loss: 0.1155 - auc: 0.7041 - accuracy: 0.9734 - val_loss: 0.1024 - val_auc: 0.7657 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00003: saving model to Checkpoint/weights.03-0.10.hdf5\n",
      "Epoch 4/100\n",
      "753/753 [==============================] - 47s 62ms/step - loss: 0.1107 - auc: 0.7059 - accuracy: 0.9748 - val_loss: 0.0983 - val_auc: 0.7574 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00004: saving model to Checkpoint/weights.04-0.10.hdf5\n",
      "Epoch 5/100\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.1129 - auc: 0.7083 - accuracy: 0.9741 - val_loss: 0.0975 - val_auc: 0.7665 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00005: saving model to Checkpoint/weights.05-0.10.hdf5\n",
      "Epoch 6/100\n",
      "753/753 [==============================] - 49s 66ms/step - loss: 0.1137 - auc: 0.7014 - accuracy: 0.9739 - val_loss: 0.1018 - val_auc: 0.7701 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00006: saving model to Checkpoint/weights.06-0.10.hdf5\n",
      "Epoch 7/100\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.1080 - auc: 0.7199 - accuracy: 0.9754 - val_loss: 0.0994 - val_auc: 0.7608 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00007: saving model to Checkpoint/weights.07-0.10.hdf5\n",
      "Epoch 8/100\n",
      "753/753 [==============================] - 49s 65ms/step - loss: 0.1086 - auc: 0.7270 - accuracy: 0.9750 - val_loss: 0.1000 - val_auc: 0.7715 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00008: saving model to Checkpoint/weights.08-0.10.hdf5\n",
      "Epoch 9/100\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.1087 - auc: 0.7474 - accuracy: 0.9743 - val_loss: 0.0962 - val_auc: 0.7712 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00009: saving model to Checkpoint/weights.09-0.10.hdf5\n",
      "Epoch 10/100\n",
      "753/753 [==============================] - 49s 65ms/step - loss: 0.1059 - auc: 0.7323 - accuracy: 0.9755 - val_loss: 0.0970 - val_auc: 0.7725 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00010: saving model to Checkpoint/weights.10-0.10.hdf5\n",
      "Epoch 11/100\n",
      "753/753 [==============================] - 48s 63ms/step - loss: 0.1055 - auc: 0.7696 - accuracy: 0.9746 - val_loss: 0.0984 - val_auc: 0.7692 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00011: saving model to Checkpoint/weights.11-0.10.hdf5\n",
      "Epoch 12/100\n",
      "753/753 [==============================] - 47s 62ms/step - loss: 0.1094 - auc: 0.7393 - accuracy: 0.9745 - val_loss: 0.0985 - val_auc: 0.7695 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00012: saving model to Checkpoint/weights.12-0.10.hdf5\n",
      "Epoch 13/100\n",
      "753/753 [==============================] - 47s 63ms/step - loss: 0.1059 - auc: 0.7483 - accuracy: 0.9749 - val_loss: 0.0957 - val_auc: 0.7751 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00013: saving model to Checkpoint/weights.13-0.10.hdf5\n",
      "Epoch 14/100\n",
      "753/753 [==============================] - 48s 63ms/step - loss: 0.0978 - auc: 0.7962 - accuracy: 0.9760 - val_loss: 0.0958 - val_auc: 0.7700 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00014: saving model to Checkpoint/weights.14-0.10.hdf5\n",
      "Epoch 15/100\n",
      "753/753 [==============================] - 48s 63ms/step - loss: 0.0993 - auc: 0.7900 - accuracy: 0.9755 - val_loss: 0.0969 - val_auc: 0.7644 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00015: saving model to Checkpoint/weights.15-0.10.hdf5\n",
      "Epoch 16/100\n",
      "753/753 [==============================] - 49s 65ms/step - loss: 0.1010 - auc: 0.8097 - accuracy: 0.9743 - val_loss: 0.0957 - val_auc: 0.7718 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00016: saving model to Checkpoint/weights.16-0.10.hdf5\n",
      "Epoch 17/100\n",
      "753/753 [==============================] - 48s 63ms/step - loss: 0.0987 - auc: 0.8216 - accuracy: 0.9745 - val_loss: 0.1003 - val_auc: 0.7340 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00017: saving model to Checkpoint/weights.17-0.10.hdf5\n",
      "Epoch 18/100\n",
      "753/753 [==============================] - 49s 65ms/step - loss: 0.0972 - auc: 0.8366 - accuracy: 0.9744 - val_loss: 0.0966 - val_auc: 0.7566 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00018: saving model to Checkpoint/weights.18-0.10.hdf5\n",
      "Epoch 19/100\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.0987 - auc: 0.8317 - accuracy: 0.9741 - val_loss: 0.0988 - val_auc: 0.7468 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00019: saving model to Checkpoint/weights.19-0.10.hdf5\n",
      "Epoch 20/100\n",
      "753/753 [==============================] - 48s 64ms/step - loss: 0.0984 - auc: 0.8518 - accuracy: 0.9727 - val_loss: 0.0980 - val_auc: 0.7457 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00020: saving model to Checkpoint/weights.20-0.10.hdf5\n",
      "Epoch 21/100\n",
      "753/753 [==============================] - 47s 63ms/step - loss: 0.0940 - auc: 0.8465 - accuracy: 0.9747 - val_loss: 0.1031 - val_auc: 0.7469 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00021: saving model to Checkpoint/weights.21-0.10.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d9a1320a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=VALIDATION_SIZE, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[checkpoint, callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:01:57.484536Z",
     "start_time": "2021-01-24T16:01:40.838154Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = np.where(model.predict(X_train)<0.5, 0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:00:01.866233Z",
     "start_time": "2021-01-24T15:59:45.829641Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, np.where(model.predict(X_train)<0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:04:00.496542Z",
     "start_time": "2021-01-24T16:04:00.471464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.01      0.02       750\n",
      "        True       0.98      1.00      0.99     29333\n",
      "\n",
      "    accuracy                           0.98     30083\n",
      "   macro avg       0.99      0.50      0.50     30083\n",
      "weighted avg       0.98      0.98      0.96     30083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:06:41.730882Z",
     "start_time": "2021-01-24T16:06:41.623995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(cm, index = ['False', 'True'], columns = ['False', 'True']), annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ITC] *",
   "language": "python",
   "name": "conda-env-ITC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}