{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "\n",
    "- building a baseline model using the cats vs. dogs architecture.\n",
    "- this baseline model includes a preprocessing steps of rescaling of all images to 80x80 size with a single channel (gray scale)\n",
    "- this baseline model is built for binary classification:\n",
    "    - output layer has a Sigmoid activation function \n",
    "    - loss function is binary_crossentropy\n",
    "    - chosen metrics is AUC with and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:30:25.026843Z",
     "start_time": "2021-01-24T16:30:23.499919Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:30:25.147957Z",
     "start_time": "2021-01-24T16:30:25.028061Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_META = 'train.csv'\n",
    "\n",
    "TRAIN_IMG_DIR = Path('train') \n",
    "TEST_IMG_DIR = Path('test') \n",
    "TRAIN_RESIZE_DIR = Path('BaselineSingleLabelCLAHE/train_resize') \n",
    "TEST_RESIZE_DIR = Path('BaselineSingleLabelCLAHE/test_resize') \n",
    "MODEL_CHECKPOINTS = 'BaselineSingleLabelCLAHE/Checkpoint/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "\n",
    "CASE = 'StudyInstanceUID'\n",
    "NEW_SIZE = (80,80)\n",
    "IMG_SIZE = (80, 80, 1)\n",
    "\n",
    "VALIDATION_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "RSCL = 1/255\n",
    "ACTIVATION = 'relu'\n",
    "N_FILTERS = 64\n",
    "FILTER2D_size = 1\n",
    "METRICS = [AUC(), 'accuracy']\n",
    "DENSE_DIM = 64\n",
    "OUT_DIM = 1\n",
    "OUT_ACTIVATION = 'sigmoid'\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'binary_crossentropy'\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "os.makedirs(TRAIN_RESIZE_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_RESIZE_DIR, exist_ok=True)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load meta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:30:25.195892Z",
     "start_time": "2021-01-24T16:30:25.149449Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_META)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:30:25.201615Z",
     "start_time": "2021-01-24T16:30:25.197000Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = df.select_dtypes(int).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:30:25.209797Z",
     "start_time": "2021-01-24T16:30:25.202635Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_img(img: np.array, ax=None, title: str='', cmap: str = 'gray'):\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.imshow(img, cmap=cmap, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "def preprocess(img_path: Path, processed_path: Path, size: tuple=NEW_SIZE, \n",
    "               scale=cv2.IMREAD_GRAYSCALE, clip_limit=None, \n",
    "               title_grid_size=None):\n",
    "    new_img = cv2.createCLAHE(clipLimit=clip_limit, \n",
    "                              tileGridSize=title_grid_size).apply(\n",
    "        cv2.resize(cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE), NEW_SIZE))\n",
    "    cv2.imwrite(str(processed_path), new_img)\n",
    "    \n",
    "\n",
    "def validate_file(record: Path):\n",
    "    if record.is_file() & record.exists():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def numipy_train(meta: pd.DataFrame, img_dir: Path, suffix: str = '.jpg', \n",
    "                 case_col: str = CASE, labels_col = labels, \n",
    "                 scale=cv2.IMREAD_GRAYSCALE, image_dir_temp_col = 'images', \n",
    "                 cpu: int=None, binary_label: str = None):\n",
    "    \n",
    "    meta[image_dir_temp_col] = img_dir / (meta[case_col] + suffix)\n",
    "    msk = meta[image_dir_temp_col].apply(validate_file)\n",
    "    meta = meta[msk]\n",
    "    if binary_label:\n",
    "        binary_label = [label for label in labels_col if binary_label in label]\n",
    "        label_values = np.any(meta[binary_label], axis=1).values\n",
    "    else:\n",
    "        label_values = meta[labels_col].values\n",
    "    images = meta[image_dir_temp_col].to_list() \n",
    "    images = [(str(image), scale) for image in images]\n",
    "    with Pool(cpu) as p: images = p.starmap(cv2.imread, images)\n",
    "    return np.array(images), label_values\n",
    "\n",
    "\n",
    "def multi_preprocess(input_dir: Path, output_dir: Path, glob: str='*.jpg',\n",
    "                      size: tuple=NEW_SIZE, scale=cv2.IMREAD_GRAYSCALE, \n",
    "                      clip_limit=None, title_grid_size=None, \n",
    "                      cpu: int=None):\n",
    "    pool_lst = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for input_img in input_dir.glob(glob):\n",
    "        pool_lst.append((input_img, output_dir/input_img.name, size, scale, clip_limit, title_grid_size))\n",
    "    with Pool(cpu) as p: p.starmap(preprocess, pool_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "## preprocess train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:11.525539Z",
     "start_time": "2021-01-24T16:30:25.210730Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_preprocess(TRAIN_IMG_DIR, TRAIN_RESIZE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:25.003698Z",
     "start_time": "2021-01-24T16:32:11.527641Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_preprocess(TEST_IMG_DIR, TEST_RESIZE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert train into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:25.922147Z",
     "start_time": "2021-01-24T16:32:25.005034Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = numipy_train(df, TRAIN_RESIZE_DIR, binary_label='CVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T15:49:34.854458Z",
     "start_time": "2021-01-23T15:49:34.851131Z"
    }
   },
   "source": [
    "# basic CNN\n",
    "\n",
    "## make sequential model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:25.974065Z",
     "start_time": "2021-01-24T16:32:25.923378Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([Rescaling(RSCL, input_shape=IMG_SIZE, name='rescaling'),\n",
    "                    Conv2D(N_FILTERS, FILTER2D_size, activation=ACTIVATION, name='conv_1'), \n",
    "                    MaxPooling2D(name='max_pool1'),  \n",
    "                    Conv2D(N_FILTERS, FILTER2D_size, activation=ACTIVATION, name='conv_2'), \n",
    "                    MaxPooling2D(name='max_pool2'), \n",
    "                    Conv2D(N_FILTERS, FILTER2D_size, activation=ACTIVATION, name='conv_3'),\n",
    "                    MaxPooling2D(name='max_pool3'), \n",
    "                    Flatten(name='flat'), \n",
    "                    Dense(DENSE_DIM, activation=ACTIVATION, name='dense_1'), \n",
    "                    Dense(1, activation=OUT_ACTIVATION, name='out')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:25.979539Z",
     "start_time": "2021-01-24T16:32:25.975111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 80, 80, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 80, 80, 64)        128       \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 40, 40, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 20, 20, 64)        4160      \n",
      "_________________________________________________________________\n",
      "max_pool3 (MaxPooling2D)     (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flat (Flatten)               (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 418,177\n",
      "Trainable params: 418,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:25.983246Z",
     "start_time": "2021-01-24T16:32:25.980450Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(MODEL_CHECKPOINTS, monitor='val_loss', verbose=1, \n",
    "save_best_only=False, save_weights_only=False, mode='auto')\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:32:25.994502Z",
     "start_time": "2021-01-24T16:32:25.984107Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:43:10.896034Z",
     "start_time": "2021-01-24T16:32:25.996017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "753/753 [==============================] - 44s 57ms/step - loss: 0.1342 - auc: 0.4973 - accuracy: 0.9659 - val_loss: 0.1062 - val_auc: 0.6373 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00001: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.01-0.11.hdf5\n",
      "Epoch 2/100\n",
      "753/753 [==============================] - 42s 56ms/step - loss: 0.1242 - auc: 0.5271 - accuracy: 0.9734 - val_loss: 0.1018 - val_auc: 0.7413 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00002: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.02-0.10.hdf5\n",
      "Epoch 3/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1171 - auc: 0.6345 - accuracy: 0.9741 - val_loss: 0.0995 - val_auc: 0.7567 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00003: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.03-0.10.hdf5\n",
      "Epoch 4/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1106 - auc: 0.6766 - accuracy: 0.9754 - val_loss: 0.0982 - val_auc: 0.7620 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00004: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.04-0.10.hdf5\n",
      "Epoch 5/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1075 - auc: 0.6714 - accuracy: 0.9764 - val_loss: 0.0996 - val_auc: 0.7651 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00005: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.05-0.10.hdf5\n",
      "Epoch 6/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1097 - auc: 0.7265 - accuracy: 0.9746 - val_loss: 0.1008 - val_auc: 0.7700 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00006: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.06-0.10.hdf5\n",
      "Epoch 7/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1105 - auc: 0.7250 - accuracy: 0.9745 - val_loss: 0.1023 - val_auc: 0.7687 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00007: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.07-0.10.hdf5\n",
      "Epoch 8/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1097 - auc: 0.7301 - accuracy: 0.9744 - val_loss: 0.0998 - val_auc: 0.7639 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00008: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.08-0.10.hdf5\n",
      "Epoch 9/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1088 - auc: 0.7474 - accuracy: 0.9744 - val_loss: 0.0980 - val_auc: 0.7610 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00009: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.09-0.10.hdf5\n",
      "Epoch 10/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1108 - auc: 0.7427 - accuracy: 0.9737 - val_loss: 0.0967 - val_auc: 0.7726 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00010: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.10-0.10.hdf5\n",
      "Epoch 11/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1056 - auc: 0.7492 - accuracy: 0.9752 - val_loss: 0.0989 - val_auc: 0.7596 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00011: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.11-0.10.hdf5\n",
      "Epoch 12/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1067 - auc: 0.7571 - accuracy: 0.9746 - val_loss: 0.0981 - val_auc: 0.7565 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00012: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.12-0.10.hdf5\n",
      "Epoch 13/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1037 - auc: 0.7935 - accuracy: 0.9745 - val_loss: 0.0997 - val_auc: 0.7679 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00013: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.13-0.10.hdf5\n",
      "Epoch 14/100\n",
      "753/753 [==============================] - 43s 57ms/step - loss: 0.1043 - auc: 0.7869 - accuracy: 0.9740 - val_loss: 0.0984 - val_auc: 0.7470 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00014: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.14-0.10.hdf5\n",
      "Epoch 15/100\n",
      "753/753 [==============================] - 44s 59ms/step - loss: 0.1015 - auc: 0.8031 - accuracy: 0.9746 - val_loss: 0.1070 - val_auc: 0.7155 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00015: saving model to BaselineSingleLabelCLAHE/Checkpoint/weights.15-0.11.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f50f8566250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=VALIDATION_SIZE, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[checkpoint, callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:43:24.983736Z",
     "start_time": "2021-01-24T16:43:10.897428Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = np.where(model.predict(X_train)<0.5, 0, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:43:40.467592Z",
     "start_time": "2021-01-24T16:43:24.985079Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, np.where(model.predict(X_train)<0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:43:40.490055Z",
     "start_time": "2021-01-24T16:43:40.468592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       750\n",
      "        True       0.98      1.00      0.99     29333\n",
      "\n",
      "    accuracy                           0.98     30083\n",
      "   macro avg       0.49      0.50      0.49     30083\n",
      "weighted avg       0.95      0.98      0.96     30083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T16:43:40.623058Z",
     "start_time": "2021-01-24T16:43:40.490962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(cm, index = ['False', 'True'], columns = ['False', 'True']), annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ITC] *",
   "language": "python",
   "name": "conda-env-ITC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
